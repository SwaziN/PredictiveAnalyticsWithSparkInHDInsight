{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Classification Model\n",
    "\n",
    "In this exercise, you will implement a classification model that uses features of a flight to predict whether or not the flight will be delayed.\n",
    "\n",
    "### Import Spark SQL and Spark ML Libraries\n",
    "\n",
    "First, import the libraries you will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HADOOP_USER_NAME\"] = \"spark\"\n",
    "os.environ[\"SPARK_MAJOR_VERSION\"] = \"2\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Source Data\n",
    "The data for this exercise is provided as a CSV file containing details of flights. The data includes specific characteristics (or *features*) for each flight, as well as a column indicating how many minutes late or early the flight arrived.\n",
    "\n",
    "You will load this data into a DataFrame and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "|        19|        5|     DL|          14107|        13487|      -7|     -13|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|\n",
      "|        19|        5|     DL|          11433|        12892|      -2|      -7|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|\n",
      "|        19|        5|     DL|          12953|        10397|      -1|      10|\n",
      "|        19|        5|     DL|          11433|        12953|      -3|     -10|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('python-classification').getOrCreate()\n",
    "spark.conf.set('spark.executor.memory', '3g')\n",
    "spark.conf.set('spark.executor.cores', '3')\n",
    "spark.conf.set('spark.cores.max', '3')\n",
    "spark.conf.set('spark.driver.memory','3g')\n",
    "csv = spark.read.csv('/user/maria_dev/data/flights.csv', inferSchema=True, header=True)\n",
    "csv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "Most modeling begins with exhaustive exploration and preparation of the data. In this example, the data has been cleaned for you. You will simply select a subset of columns to use as *features* and create a Boolean *label* field named **Late** with the value **1** for flights that arrived 15 minutes or more after the scheduled arrival time, or **0** if the flight was early or on-time.\n",
    "\n",
    "(Note that in a real scenario, you would perform additional tasks such as handling missing or duplicated data, scaling numeric columns, and using a process called *feature engineering* to create new features for your model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------------+-------------+--------+----+\n",
      "|DayofMonth|DayOfWeek|OriginAirportID|DestAirportID|DepDelay|Late|\n",
      "+----------+---------+---------------+-------------+--------+----+\n",
      "|        19|        5|          11433|        13303|      -3|   0|\n",
      "|        19|        5|          14869|        12478|       0|   0|\n",
      "|        19|        5|          14057|        14869|      -4|   0|\n",
      "|        19|        5|          15016|        11433|      28|   1|\n",
      "|        19|        5|          11193|        12892|      -6|   0|\n",
      "|        19|        5|          10397|        15016|      -1|   0|\n",
      "|        19|        5|          15016|        10397|       0|   0|\n",
      "|        19|        5|          10397|        14869|      15|   1|\n",
      "|        19|        5|          10397|        10423|      33|   1|\n",
      "|        19|        5|          11278|        10397|     323|   1|\n",
      "|        19|        5|          14107|        13487|      -7|   0|\n",
      "|        19|        5|          11433|        11298|      22|   1|\n",
      "|        19|        5|          11298|        11433|      40|   1|\n",
      "|        19|        5|          11433|        12892|      -2|   0|\n",
      "|        19|        5|          10397|        12451|      71|   1|\n",
      "|        19|        5|          12451|        10397|      75|   1|\n",
      "|        19|        5|          12953|        10397|      -1|   0|\n",
      "|        19|        5|          11433|        12953|      -3|   0|\n",
      "|        19|        5|          10397|        14771|      31|   1|\n",
      "|        19|        5|          13204|        10397|       8|   1|\n",
      "+----------+---------+---------------+-------------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = csv.select(\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", \n",
    "                  ((col(\"ArrDelay\") > 15).cast(\"Int\").alias(\"Late\")))\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data\n",
    "It is common practice when building supervised machine learning models to split the source data, using some of it to train the model and reserving some to test the trained model. In this exercise, you will use 70% of the data for training, and reserve 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 1890294  Testing Rows: 811924\n"
     ]
    }
   ],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()\n",
    "print \"Training Rows:\", train_rows, \" Testing Rows:\", test_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Training Data\n",
    "To train the classification model, you need a training data set that includes a vector of numeric features, and a label column. In this exercise, you will use the **VectorAssembler** class to transform the feature columns into a vector, and then rename the **Late** column to **label**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    1|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "|[1.0,1.0,10140.0,...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols = [\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\"], outputCol=\"features\")\n",
    "training = assembler.transform(train).select(col(\"features\"), col(\"Late\").alias(\"label\"))\n",
    "training.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Classification Model\n",
    "Next, you need to train a classification model using the training data. To do this, create an instance of the classification algorithm you want to use and use its **fit** method to train a model based on the training DataFrame. In this exercise, you will use a *Logistic Regression* classification algorithm - though you can use the same technique for any of the classification algorithms supported in the spark.ml API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained!\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\",featuresCol=\"features\",maxIter=10,regParam=0.3)\n",
    "model = lr.fit(training)\n",
    "print \"Model trained!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Testing Data\n",
    "Now that you have a trained model, you can test it using the testing data you reserved previously. First, you need to prepare the testing data in the same way as you did the training data by transforming the feature columns into a vector. This time you'll rename the **Late** column to **trueLabel**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|trueLabel|\n",
      "+--------------------+---------+\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        1|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        1|\n",
      "|[1.0,1.0,10140.0,...|        1|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        1|\n",
      "|[1.0,1.0,10140.0,...|        1|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "|[1.0,1.0,10140.0,...|        0|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing = assembler.transform(test).select(col(\"features\"), col(\"Late\").alias(\"trueLabel\"))\n",
    "testing.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "Now you're ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict delay status for flights where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted status to the actual status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------+-------------+---------+\n",
      "|            features|prediction|probability_0|probability_1|trueLabel|\n",
      "+--------------------+----------+-------------+-------------+---------+\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.82338965|   0.17661035|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.80664915|   0.19335085|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.61269796|   0.38730207|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8258132|    0.1741868|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8237823|   0.17621765|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.7767898|   0.22321022|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.7767898|   0.22321022|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|     0.839528|   0.16047196|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.82784027|   0.17215972|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.81548834|   0.18451165|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.84141487|   0.15858513|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|     0.831812|   0.16818799|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8133672|   0.18663281|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.74354535|   0.25645462|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.83418924|   0.16581076|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.83418924|   0.16581076|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|     0.832329|     0.167671|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.82654715|   0.17345284|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.82654715|   0.17345284|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.82452303|   0.17547695|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.84394056|   0.15605943|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8305413|   0.16945872|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8285541|   0.17144588|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8265485|   0.17345148|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.81624204|   0.18375796|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.7652905|    0.2347095|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.82466316|   0.17533681|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8246786|    0.1753214|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8387475|   0.16125248|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8329634|   0.16703658|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.83691347|   0.16308656|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8290946|   0.17090538|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8230373|   0.17696269|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.77097493|    0.2290251|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|   0.79741406|    0.2025859|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|    0.8374558|   0.16254419|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|   0.83165973|   0.16834027|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.8300792|   0.16992082|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|   0.83243793|   0.16756207|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|   0.83078563|   0.16921437|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.8368852|   0.16311482|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|   0.76360226|   0.23639776|        1|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.8464843|   0.15351567|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.8521563|   0.14784373|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.8374238|   0.16257621|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.8335607|   0.16643932|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.8215307|   0.17846932|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.8215307|   0.17846932|        1|\n",
      "|[1.0,1.0,10299.0,...|       0.0|     0.813139|   0.18686096|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.8044467|   0.19555327|        1|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.8022264|   0.19777358|        1|\n",
      "|[1.0,1.0,10299.0,...|       0.0|    0.7212248|   0.27877522|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.83182096|   0.16817902|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.82785213|   0.17214788|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|      0.82584|   0.17415999|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8238094|   0.17619058|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.83186746|   0.16813253|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8298927|   0.17010733|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.81974155|   0.18025844|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.7299966|   0.27000338|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8319394|   0.16806062|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.82996523|   0.17003475|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.82996523|   0.17003475|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8279727|   0.17202727|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.83584476|   0.16415524|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8319517|   0.16804834|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8319517|   0.16804834|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8279852|   0.17201477|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.82597435|   0.17402564|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.82597435|   0.17402564|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8177453|    0.1822547|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8135187|   0.18648128|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|     0.800387|   0.19961298|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.7981322|    0.2018678|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.7842044|   0.21579559|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.77453935|   0.22546066|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.7695931|    0.2304069|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.6556258|    0.3443742|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8339382|   0.16606182|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.82801694|   0.17198306|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.7866106|   0.21338941|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8378066|   0.16219342|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.83395076|   0.16604923|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8319955|   0.16800451|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8319955|   0.16800451|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.83002186|   0.16997811|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.83002186|   0.16997811|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.83002186|   0.16997811|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8260194|   0.17398056|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.8260194|   0.17398056|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.82399046|   0.17600952|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|     0.817792|   0.18220797|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.78187007|    0.2181299|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.7770384|   0.22296162|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.76714766|   0.23285234|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|   0.76714766|   0.23285234|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.7620891|   0.23791093|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.7595316|    0.2404684|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|    0.7356788|   0.26432118|        1|\n",
      "|[1.0,1.0,10397.0,...|       1.0|    0.1540977|   0.84590226|        1|\n",
      "+--------------------+----------+-------------+-------------+---------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "prediction = model.transform(testing)\n",
    "firstelement=udf(lambda v:float(v[0]),FloatType())\n",
    "secondelement=udf(lambda v:float(v[1]),FloatType())\n",
    "predicted = prediction.select(\"features\", \"prediction\", \n",
    "                              firstelement(col(\"probability\")).alias(\"probability_0\"), \n",
    "                              secondelement(col(\"probability\")).alias(\"probability_1\"),\n",
    "                              \"trueLabel\")\n",
    "predicted.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the result, the **prediction** column contains the predicted value for the label, and the **trueLabel** column contains the actual known value from the testing data. It looks like there are a mix of correct and incorrect predictions - later in this course you'll learn how to measure the accuracy of a model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
