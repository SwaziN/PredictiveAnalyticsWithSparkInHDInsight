{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Model Parameters\n",
    "\n",
    "In this exercise, you will optimise the parameters for a classification model.\n",
    "\n",
    "### Prepare the Data\n",
    "\n",
    "First, import the libraries you will need and prepare the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HADOOP_USER_NAME\"] = \"spark\"\n",
    "os.environ[\"SPARK_MAJOR_VERSION\"] = \"2\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import Spark SQL and Spark ML libraries\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('python-parameter-tuning').getOrCreate()\n",
    "spark.conf.set('spark.executor.memory', '3g')\n",
    "spark.conf.set('spark.executor.cores', '3')\n",
    "spark.conf.set('spark.cores.max', '3')\n",
    "spark.conf.set('spark.driver.memory','3g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the source data\n",
    "csv = spark.read.csv('/user/maria_dev/data/flights.csv', inferSchema=True, header=True)\n",
    "\n",
    "# Select features and label\n",
    "data = csv.select(\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", ((col(\"ArrDelay\") > 15).cast(\"Int\").alias(\"label\")))\n",
    "\n",
    "# Split the data\n",
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Pipeline\n",
    "Now define a pipeline that creates a feature vector and trains a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "assembler = VectorAssembler(inputCols = [\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\"], outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[assembler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters\n",
    "You can tune parameters to find the best model for your data. A simple way to do this is to use  **TrainValidationSplit** to evaluate each combination of parameters defined in a **ParameterGrid** against a subset of the training data in order to find the best performing parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.1, 0.01]).addGrid(lr.maxIter, [10, 5]).addGrid(lr.threshold, [0.35, 0.30]).build()\n",
    "tvs = TrainValidationSplit(estimator=pipeline, evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\n",
    "\n",
    "model = tvs.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "Now you're ready to apply the model to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+---------+\n",
      "|            features|prediction|         probability|trueLabel|\n",
      "+--------------------+----------+--------------------+---------+\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.89152309189313...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.86011603366836...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.90805384511236...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.90147768869811...|        0|\n",
      "|[1.0,1.0,10140.0,...|       1.0|[0.63043653180965...|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.92012041768991...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.90815291522121...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.90158307652015...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.89459783850171...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.86214225810458...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.94795951519727...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.94406166381961...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.93542930912138...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.92556984324303...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.90817091765642...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.90160222714948...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.89461818949124...|        0|\n",
      "|[1.0,1.0,10140.0,...|       1.0|[0.38768950921374...|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.90441569210213...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.89037564289530...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.72098636728543...|        0|\n",
      "|[1.0,1.0,10140.0,...|       1.0|[6.77613819480584...|        1|\n",
      "|[1.0,1.0,10140.0,...|       1.0|[0.52802722340036...|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.92320061598220...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.90656447945746...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.74093195089682...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.75533551717359...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.90089049766854...|        0|\n",
      "|[1.0,1.0,10140.0,...|       1.0|[0.44132881376807...|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.86376620875222...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.85452995799344...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.91006335273481...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.88947246324880...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.94916481449577...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.94535203616857...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.93223888387584...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.91021046602307...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.88192784195561...|        0|\n",
      "|[1.0,1.0,10140.0,...|       1.0|[0.60048834958133...|        1|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.87599553087872...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.91800761834331...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.88430431669595...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.93850667711859...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.91242576928004...|        0|\n",
      "|[1.0,1.0,10140.0,...|       0.0|[0.89405186722366...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.91808805162366...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.95181319395199...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.90477934072495...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.91909072310414...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.94029928818767...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.91490974065878...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.95265699323264...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.95617568373855...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.93708629870593...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.93243208815438...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.96566394913602...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.95396508350114...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.94677485267085...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.94279362431242...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.93853393432065...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.92911259765354...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.90617015026934...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.89235713536179...|        1|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.88480074636583...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.85932009420061...|        0|\n",
      "|[1.0,1.0,10299.0,...|       0.0|[0.94284017222335...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.89138879616340...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.73810262326466...|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91247464222978...|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.90618200193980...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.82931055332924...|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.79440807799545...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.76834817064868...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.92419379257348...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91866860250005...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91866860250005...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91910832855193...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91324727386726...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91324727386726...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.90036154971383...|        0|\n",
      "|[1.0,1.0,10397.0,...|       1.0|[0.01971208307697...|        1|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91918318670551...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91332704443416...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.90708944760003...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.88590304869519...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.86953600030406...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.67953553676489...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91937272242906...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91352902226194...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.90730448591187...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.86093389294675...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.80866004347907...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.79656765973050...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.93005889741781...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.92492646475489...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.92492646475489...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.92492646475489...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91945002171980...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91945002171980...|        0|\n",
      "|[1.0,1.0,10397.0,...|       0.0|[0.91361139761033...|        0|\n",
      "+--------------------+----------+--------------------+---------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(test)\n",
    "predicted = prediction.select(\"features\", \"prediction\", \"probability\", \"trueLabel\")\n",
    "predicted.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Confusion Matrix Metrics\n",
    "Classifiers are typically evaluated by creating a *confusion matrix*, which indicates the number of:\n",
    "- True Positives\n",
    "- True Negatives\n",
    "- False Positives\n",
    "- False Negatives\n",
    "\n",
    "From these core measures, other evaluation metrics such as *precision* and *recall* can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|          113347.0|\n",
      "|       FP|           11409.0|\n",
      "|       TN|          637545.0|\n",
      "|       FN|           48266.0|\n",
      "|Precision|0.9085494886017507|\n",
      "|   Recall|0.7013482826257789|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "metrics = spark.createDataFrame([\n",
    " (\"TP\", tp),\n",
    " (\"FP\", fp),\n",
    " (\"TN\", tn),\n",
    " (\"FN\", fn),\n",
    " (\"Precision\", tp / (tp + fp)),\n",
    " (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\n",
    "metrics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Area Under ROC\n",
    "Another way to assess the performance of a classification model is to measure the area under a ROC curve for the model. the spark.ml library includes a **BinaryClassificationEvaluator** class that you can use to compute this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR =  0.841883841846\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "aur = evaluator.evaluate(prediction)\n",
    "print \"AUR = \", aur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param (regParam): 0.01\n",
      "Best Param (maxIter): 10\n",
      "Best Param (threshold): 0.35\n"
     ]
    }
   ],
   "source": [
    "bestModel = model.bestModel.stages[-1]\n",
    "print('Best Param (regParam): {0}'.format(bestModel._java_obj.getRegParam()))\n",
    "print('Best Param (maxIter): {0}'.format(bestModel._java_obj.getMaxIter()))\n",
    "print('Best Param (threshold): {0}'.format(bestModel._java_obj.getThreshold()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
