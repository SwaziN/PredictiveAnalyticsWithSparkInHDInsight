{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data with DataFrames and Spark SQL\n",
    "In this exercise, you will explore data using the Spark DataFrames API and Spark SQL.\n",
    "\n",
    "### Load Data Using an Explicit Schema\n",
    "To explore data, you must load it into a programmatic data object such as a DataFrame. If the structure of the data is known ahead of time, you can explicitly specify the schema for the DataFrame.\n",
    "\n",
    "In this exercise, you will work with data that records details of flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c12222b50947c78d4052a348c680f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TWFnaWNzQ29udHJvbGxlcldpZGdldChjaGlsZHJlbj0oVGFiKGNoaWxkcmVuPShNYW5hZ2VTZXNzaW9uV2lkZ2V0KGNoaWxkcmVuPShIVE1MKHZhbHVlPXUnPGJyLz4nKSwgSFRNTCh2YWx1ZT3igKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HADOOP_USER_NAME\"] = \"spark\"\n",
    "os.environ[\"SPARK_MAJOR_VERSION\"] = \"2\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "|        19|        5|     DL|          14107|        13487|      -7|     -13|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|\n",
      "|        19|        5|     DL|          11433|        12892|      -2|      -7|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|\n",
      "|        19|        5|     DL|          12953|        10397|      -1|      10|\n",
      "|        19|        5|     DL|          11433|        12953|      -3|     -10|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "flightSchema = StructType([\n",
    "  StructField(\"DayofMonth\", IntegerType(), False),\n",
    "  StructField(\"DayOfWeek\", IntegerType(), False),\n",
    "  StructField(\"Carrier\", StringType(), False),\n",
    "  StructField(\"OriginAirportID\", IntegerType(), False),\n",
    "  StructField(\"DestAirportID\", IntegerType(), False),\n",
    "  StructField(\"DepDelay\", IntegerType(), False),\n",
    "  StructField(\"ArrDelay\", IntegerType(), False),\n",
    "])\n",
    "spark = SparkSession.builder.appName('python-data-exploration').getOrCreate()\n",
    "flights = spark.read.csv('/user/maria_dev/data/raw-flight-data.csv', \n",
    "                         schema=flightSchema, header=True)\n",
    "flights.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer a Data Schema\n",
    "If the structure of the data source is unknown, you can have Spark auomatically infer the schema.\n",
    "\n",
    "In this case, you will load data about airports without knowing the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+--------------------+\n",
      "|airport_id|       city|state|                name|\n",
      "+----------+-----------+-----+--------------------+\n",
      "|     10165|Adak Island|   AK|                Adak|\n",
      "|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n",
      "|     10304|      Aniak|   AK|       Aniak Airport|\n",
      "|     10754|     Barrow|   AK|Wiley Post/Will R...|\n",
      "|     10551|     Bethel|   AK|      Bethel Airport|\n",
      "|     10926|    Cordova|   AK|Merle K Mudhole S...|\n",
      "|     14709|  Deadhorse|   AK|   Deadhorse Airport|\n",
      "|     11336| Dillingham|   AK|  Dillingham Airport|\n",
      "|     11630|  Fairbanks|   AK|Fairbanks Interna...|\n",
      "|     11997|   Gustavus|   AK|    Gustavus Airport|\n",
      "|     12523|     Juneau|   AK|Juneau International|\n",
      "|     12819|  Ketchikan|   AK|Ketchikan Interna...|\n",
      "|     10245|King Salmon|   AK| King Salmon Airport|\n",
      "|     10170|     Kodiak|   AK|      Kodiak Airport|\n",
      "|     13970|   Kotzebue|   AK| Ralph Wien Memorial|\n",
      "|     13873|       Nome|   AK|        Nome Airport|\n",
      "|     14256| Petersburg|   AK|Petersburg James ...|\n",
      "|     14828|      Sitka|   AK|Sitka Rocky Gutie...|\n",
      "|     12807| St. Mary's|   AK|  St. Mary's Airport|\n",
      "|     11445|   Unalaska|   AK|    Unalaska Airport|\n",
      "+----------+-----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports = spark.read.csv('/user/maria_dev/data/airports.csv', header=True, inferSchema=True)\n",
    "airports.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use DataFrame Methods\n",
    "Spark DataFrames provide functions that you can use to extract and manipulate data. For example, you can use the **select** function to return a new DataFrame containing columns selected from an existing DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------------------+\n",
      "|city       |name                               |\n",
      "+-----------+-----------------------------------+\n",
      "|Adak Island|Adak                               |\n",
      "|Anchorage  |Ted Stevens Anchorage International|\n",
      "|Aniak      |Aniak Airport                      |\n",
      "|Barrow     |Wiley Post/Will Rogers Memorial    |\n",
      "|Bethel     |Bethel Airport                     |\n",
      "|Cordova    |Merle K Mudhole Smith              |\n",
      "|Deadhorse  |Deadhorse Airport                  |\n",
      "|Dillingham |Dillingham Airport                 |\n",
      "|Fairbanks  |Fairbanks International            |\n",
      "|Gustavus   |Gustavus Airport                   |\n",
      "|Juneau     |Juneau International               |\n",
      "|Ketchikan  |Ketchikan International            |\n",
      "|King Salmon|King Salmon Airport                |\n",
      "|Kodiak     |Kodiak Airport                     |\n",
      "|Kotzebue   |Ralph Wien Memorial                |\n",
      "|Nome       |Nome Airport                       |\n",
      "|Petersburg |Petersburg James A Johnson         |\n",
      "|Sitka      |Sitka Rocky Gutierrez              |\n",
      "|St. Mary's |St. Mary's Airport                 |\n",
      "|Unalaska   |Unalaska Airport                   |\n",
      "+-----------+-----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities = airports.select(\"city\", \"name\")\n",
    "cities.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Operations\n",
    "You can combine functions in a single statement to perform multiple operations on a DataFrame. In this case, you will use the **join** function to combine the **flights** and **airports** DataFrames, and then use the **groupBy** and **count** functions to return the number of flights from each airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|             city| count|\n",
      "+-----------------+------+\n",
      "|          Phoenix| 90281|\n",
      "|            Omaha| 13537|\n",
      "|   Raleigh/Durham| 28436|\n",
      "|        Anchorage|  7777|\n",
      "|           Dallas| 19503|\n",
      "|          Oakland| 25503|\n",
      "|      San Antonio| 23090|\n",
      "|       Louisville| 10953|\n",
      "|     Philadelphia| 47659|\n",
      "|Dallas/Fort Worth|105024|\n",
      "|      Los Angeles|118684|\n",
      "|       Sacramento| 25193|\n",
      "|     Indianapolis| 18099|\n",
      "|        Cleveland| 25261|\n",
      "|        San Diego| 45783|\n",
      "|    San Francisco| 84675|\n",
      "|        Nashville| 34927|\n",
      "|    Oklahoma City| 13967|\n",
      "|          Detroit| 62879|\n",
      "|         Portland| 30640|\n",
      "+-----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsByOrigin = flights.join(airports, flights.OriginAirportID == airports.airport_id).groupBy(\"city\").count()\n",
    "flightsByOrigin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the Rows in a DataFrame\n",
    "Now that you're familiar with working with DataFrames, a key task when building predictive solutions is to explore the data, determing statistics that will help you understand the data before building predictive models. For example, how many rows of flight data do you actually have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2719418"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Summary Statistics\n",
    "Predictive modeling is based on statistics and probability, so you will often start by looking at summary statistics. The **describe** function returns a DataFrame containing the **count**, **mean**, **standard deviation**, **minimum**, and **maximum** values for each numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DayofMonth</th>\n",
       "      <td>2719418</td>\n",
       "      <td>15.79747468024408</td>\n",
       "      <td>8.799860168985367</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DayOfWeek</th>\n",
       "      <td>2719418</td>\n",
       "      <td>3.8983907586108497</td>\n",
       "      <td>1.9859881390373617</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carrier</th>\n",
       "      <td>2719418</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9E</td>\n",
       "      <td>YV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OriginAirportID</th>\n",
       "      <td>2719418</td>\n",
       "      <td>12742.26441172339</td>\n",
       "      <td>1501.9729397025808</td>\n",
       "      <td>10140</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DestAirportID</th>\n",
       "      <td>2719418</td>\n",
       "      <td>12742.455345592329</td>\n",
       "      <td>1501.9692528927785</td>\n",
       "      <td>10140</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DepDelay</th>\n",
       "      <td>2691974</td>\n",
       "      <td>10.53686662649788</td>\n",
       "      <td>36.09952806643081</td>\n",
       "      <td>-63</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArrDelay</th>\n",
       "      <td>2690385</td>\n",
       "      <td>6.63768791455498</td>\n",
       "      <td>38.64881489390021</td>\n",
       "      <td>-94</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                   1                   2      3      4\n",
       "summary            count                mean              stddev    min    max\n",
       "DayofMonth       2719418   15.79747468024408   8.799860168985367      1     31\n",
       "DayOfWeek        2719418  3.8983907586108497  1.9859881390373617      1      7\n",
       "Carrier          2719418                None                None     9E     YV\n",
       "OriginAirportID  2719418   12742.26441172339  1501.9729397025808  10140  15376\n",
       "DestAirportID    2719418  12742.455345592329  1501.9692528927785  10140  15376\n",
       "DepDelay         2691974   10.53686662649788   36.09952806643081    -63   1863\n",
       "ArrDelay         2690385    6.63768791455498   38.64881489390021    -94   1845"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the Presence of Duplicates\n",
    "The data you have to work with won't always be perfect - often you'll want to *clean* the data; for example to detect and remove duplicates that might affect your model. You can use the **dropDuplicates** function to create a new DataFrame with the duplicates removed, enabling you to determine how many rows are duplicates of other rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22435"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.count() - flights.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Missing Values\n",
    "As well as determing if duplicates exist in your data, you should detect missing values, and either remove rows containing missing data or replace the missing values with a suitable relacement. The **dropna** function creates a DataFrame with any rows containing missing data removed - you can specify a subset of columns, and whether the row should be removed in *any* or *all* values are missing. You can then use this new DataFrame to determine how many rows contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46233"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.count() - flights.dropDuplicates().dropna(how=\"any\", subset=[\"ArrDelay\", \"DepDelay\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "Now that you've identified that there are duplicates and missing values, you can clean the data by removing the duplicates and replacing the missing values. The **fillna** function replaces missing values with a specified replacement value. In this case, you'll remove all duplicate rows and replace missing **ArrDelay** and **DepDelay** values with **0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2696983"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=flights.dropDuplicates().fillna(value=0, subset=[\"ArrDelay\", \"DepDelay\"])\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Summary Statistics\n",
    "After cleaning the data, you should re-check the statistics - removing rows and changing values may affect the distribution of the data, which in turn could affect any predictive models you might create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DayofMonth</th>\n",
       "      <td>2696983</td>\n",
       "      <td>15.798996508320593</td>\n",
       "      <td>8.80126719913545</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DayOfWeek</th>\n",
       "      <td>2696983</td>\n",
       "      <td>3.900369412784582</td>\n",
       "      <td>1.9864582421701982</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carrier</th>\n",
       "      <td>2696983</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9E</td>\n",
       "      <td>YV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OriginAirportID</th>\n",
       "      <td>2696983</td>\n",
       "      <td>12742.459424846207</td>\n",
       "      <td>1502.0359941370616</td>\n",
       "      <td>10140</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DestAirportID</th>\n",
       "      <td>2696983</td>\n",
       "      <td>12742.85937657004</td>\n",
       "      <td>1501.9939589817975</td>\n",
       "      <td>10140</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DepDelay</th>\n",
       "      <td>2696983</td>\n",
       "      <td>10.531134234068217</td>\n",
       "      <td>36.06172819056574</td>\n",
       "      <td>-63</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArrDelay</th>\n",
       "      <td>2696983</td>\n",
       "      <td>6.6679285705545785</td>\n",
       "      <td>38.58386147358073</td>\n",
       "      <td>-94</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                   1                   2      3      4\n",
       "summary            count                mean              stddev    min    max\n",
       "DayofMonth       2696983  15.798996508320593    8.80126719913545      1     31\n",
       "DayOfWeek        2696983   3.900369412784582  1.9864582421701982      1      7\n",
       "Carrier          2696983                None                None     9E     YV\n",
       "OriginAirportID  2696983  12742.459424846207  1502.0359941370616  10140  15376\n",
       "DestAirportID    2696983   12742.85937657004  1501.9939589817975  10140  15376\n",
       "DepDelay         2696983  10.531134234068217   36.06172819056574    -63   1863\n",
       "ArrDelay         2696983  6.6679285705545785   38.58386147358073    -94   1845"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Relationships in the Data\n",
    "Predictive modeling is largely based on statistical relationships between fields in the data. To design a good model, you need to understand how the data points relate to one another and identify any apparent correlation. The **corr** function calculates a correlation value between -1 and 1, indicating the strength of correlation between two fields. A strong positive correlation (near 1) indicates that high values for one column are often found with high values for the other, which a string negative correlation (near -1) indicates that *low* values for one column are often found with *high* values for the other. A correlation near 0 indicates little apparent relationship between the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9392630367706962"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr(\"DepDelay\", \"ArrDelay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Spark SQL\n",
    "In addition to using the DataFrame API directly to query data, you can persist DataFrames as table and use Spark SQL to query them using the SQL language. SQL is often more intuitive to use when querying tabular data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|DayOfWeek|          AvgDelay|\n",
      "+---------+------------------+\n",
      "|        1| 7.077989660973244|\n",
      "|        2|  4.39237404158651|\n",
      "|        3| 7.234625279280266|\n",
      "|        4|10.775574715480056|\n",
      "|        5|  8.71110560964396|\n",
      "|        6|2.1437428120738304|\n",
      "|        7|  5.25403935972552|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.createOrReplaceTempView(\"flightData\")\n",
    "spark.sql(\"SELECT DayOfWeek, AVG(ArrDelay) AS AvgDelay FROM flightData GROUP BY DayOfWeek ORDER BY DayOfWeek\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Inline SQL *Magic*\n",
    "Jupyter Notebooks support *magics*, which enable you to include inline code and functionality. For example, the **%%sql** magic enables you to write SQL queries and visualize the results directly in the notebook.\n",
    "\n",
    "Run the following query, and view the table of results that is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%sql` not found.\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT DepDelay, ArrDelay FROM flightData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the **Table** visualization of results above to a **Scatter** visualization to see the relationship between the **DepDelay** and **ArrDelay** values more clearly (use the **-** function to plot the actual values) - visualizations like this make it easier to show relationships as apparent *structure* in the data. For example, the positive correlation between **DepDelay** and **ArrDelay** seems to be a linear relationsip, creaing a diagonal line of plotted points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Multiple Tables\n",
    "You can create and query multiple temporary tables. Run the cells below to create a temporary table from the **airports** DataFrame, and then use an inline query to query it together with the flights data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.createOrReplaceTempView(\"airportData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%sql` not found.\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT a.name, AVG(f.ArrDelay) AS avgdelay\n",
    "FROM flightData AS f JOIN airportData AS a\n",
    "ON f.DestAirportID = a.airport_id\n",
    "GROUP BY a.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw previously, it can sometimes be useful to visualize the results of a query. Change the visualization above to a **Bar** chart, using the **-** function, to see the everage lateness (or earliness) of flights at all destinations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
